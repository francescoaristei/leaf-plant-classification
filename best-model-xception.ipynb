{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nfrom sklearn.utils import class_weight\nimport math \n\nfrom keras.applications import xception\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.xception import preprocess_input\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntfk = tf.keras\ntfkl = tf.keras.layers\n\n!pip install split-folders #to slpit the dataset in training-validation-test\nimport splitfolders","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-27T10:46:33.078955Z","iopub.execute_input":"2021-11-27T10:46:33.079272Z","iopub.status.idle":"2021-11-27T10:46:47.580023Z","shell.execute_reply.started":"2021-11-27T10:46:33.079194Z","shell.execute_reply":"2021-11-27T10:46:47.579074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random fixed seed for reproducibility\nseed = 2113\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T10:46:51.746181Z","iopub.execute_input":"2021-11-27T10:46:51.746852Z","iopub.status.idle":"2021-11-27T10:46:51.752843Z","shell.execute_reply.started":"2021-11-27T10:46:51.746811Z","shell.execute_reply":"2021-11-27T10:46:51.751346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset and training folders\ndataset_dir = '/kaggle/input/leafdataset'\ntrain_dir = os.path.join(dataset_dir, 'training')\nlabels = [\n    \"Apple\",\n    \"Blueberry\",\n    \"Cherry\",\n    \"Corn\",\n    \"Grape\",\n    \"Orange\",\n    \"Peach\",\n    \"Pepper\",\n    \"Potato\",\n    \"Raspberry\",\n    \"Soybean\",\n    \"Squash\",\n    \"Strawberry\",\n    \"Tomato\"\n]","metadata":{"execution":{"iopub.status.busy":"2021-11-27T10:47:19.634088Z","iopub.execute_input":"2021-11-27T10:47:19.634391Z","iopub.status.idle":"2021-11-27T10:47:19.639998Z","shell.execute_reply.started":"2021-11-27T10:47:19.63436Z","shell.execute_reply":"2021-11-27T10:47:19.639086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot example images from dataset\n\nnum_row = len(labels)//2\nnum_col = len(labels)//num_row\nfig, axes = plt.subplots(num_row, num_col, figsize=(2*num_row,15*num_col))\nfor i in range(len(labels)):\n  if i < len(labels):\n    class_imgs = next(os.walk('{}/{}/'.format(train_dir, labels[i])))[2]\n    class_img = class_imgs[0]\n    img = Image.open('{}/{}/{}'.format(train_dir, labels[i], class_img))\n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(np.array(img))\n    ax.set_title('{}'.format(labels[i]))\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-27T10:47:22.664578Z","iopub.execute_input":"2021-11-27T10:47:22.665043Z","iopub.status.idle":"2021-11-27T10:47:38.51193Z","shell.execute_reply.started":"2021-11-27T10:47:22.665008Z","shell.execute_reply":"2021-11-27T10:47:38.511056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset preprocessing\nWe used the metohd 'ratio' of the splitfoldres library to divide the dataset into training, validation and test sets. We decided to keep a 70% of the dataset for the training in order to obtain a well-trained model, a validation of 20% in order to keep track of the model's behaviour on a different set of data during training and also, even if not required, we decided to use part of the data (10%) for testing the performance of model prediction.","metadata":{}},{"cell_type":"code","source":"splitfolders.ratio(\"/kaggle/input/leafdataset/training\", output=\"output\", seed=seed, ratio=(.7, .2, .1), group_prefix=None) # default values","metadata":{"execution":{"iopub.status.busy":"2021-11-27T10:54:16.424099Z","iopub.execute_input":"2021-11-27T10:54:16.424381Z","iopub.status.idle":"2021-11-27T10:56:15.442162Z","shell.execute_reply.started":"2021-11-27T10:54:16.424349Z","shell.execute_reply":"2021-11-27T10:56:15.441345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset folders \noutput_dir = './output'\ntraining_dir = os.path.join(output_dir, 'train')\nvalidation_dir = os.path.join(output_dir, 'val')\ntest_dir = os.path.join(output_dir, 'test')","metadata":{"execution":{"iopub.status.busy":"2021-11-27T10:56:15.443877Z","iopub.execute_input":"2021-11-27T10:56:15.444321Z","iopub.status.idle":"2021-11-27T10:56:15.449321Z","shell.execute_reply.started":"2021-11-27T10:56:15.444269Z","shell.execute_reply":"2021-11-27T10:56:15.448264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data Augmentation on training set (but not on validation and test set)\ntrain_data_gen = ImageDataGenerator(rotation_range=0.3, \n                     height_shift_range=0.4,\n                     width_shift_range=0.4,\n                     zoom_range=0.4,\n                     horizontal_flip=True,\n                     vertical_flip=True,\n                     fill_mode='reflect',\n                     rescale=1/255)\nvalid_data_gen = ImageDataGenerator(rescale=1/255)\ntest_data_gen = ImageDataGenerator(rescale=1/255)\n\ntrain_gen = train_data_gen.flow_from_directory(directory=training_dir, \n                                              target_size=(256, 256), \n                                              color_mode='rgb',\n                                              classes=None, \n                                              batch_size=20, \n                                              shuffle=True, \n                                              seed=seed) \nvalid_gen = valid_data_gen.flow_from_directory(directory=validation_dir, \n                                              target_size=(256, 256),\n                                              color_mode='rgb',\n                                              classes=None,\n                                              batch_size=20,\n                                              shuffle=False,\n                                              seed=seed)\ntest_gen = test_data_gen.flow_from_directory(directory=test_dir, \n                                              target_size=(256, 256),\n                                              color_mode='rgb',\n                                              classes=None,\n                                              batch_size=20,\n                                              shuffle=False,\n                                              seed=seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T10:58:06.60533Z","iopub.execute_input":"2021-11-27T10:58:06.605984Z","iopub.status.idle":"2021-11-27T10:58:07.578596Z","shell.execute_reply.started":"2021-11-27T10:58:06.605946Z","shell.execute_reply":"2021-11-27T10:58:07.577841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute weigths for each class to handle the unbalanced dataset\nclass_weights = class_weight.compute_class_weight(\n           'balanced',\n            classes=np.unique(train_gen.classes), \n            y=train_gen.classes)\n\ndataset_stats = {}\n\nfor i, label in enumerate(labels):\n    files = os.listdir(os.path.join(train_dir, label))\n    dataset_stats[i] = [label, len(files)]\ndf = pd.DataFrame.from_dict(dataset_stats, orient=\"index\", columns=[\"Category\", \"Size\"])\ndf[\"Weight\"] = class_weights\n\ndf\n","metadata":{"execution":{"iopub.status.busy":"2021-11-27T10:59:40.858761Z","iopub.execute_input":"2021-11-27T10:59:40.859124Z","iopub.status.idle":"2021-11-27T10:59:40.906207Z","shell.execute_reply.started":"2021-11-27T10:59:40.859087Z","shell.execute_reply":"2021-11-27T10:59:40.905347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map class labels to weigths\nweights={}\n\nfor i in range(len(class_weights)):\n    weights[i] = class_weights[i]\n\nweights\n","metadata":{"execution":{"iopub.status.busy":"2021-11-27T11:00:11.221359Z","iopub.execute_input":"2021-11-27T11:00:11.221686Z","iopub.status.idle":"2021-11-27T11:00:11.23475Z","shell.execute_reply.started":"2021-11-27T11:00:11.221647Z","shell.execute_reply":"2021-11-27T11:00:11.234042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (256, 256, 3)\nepochs = 400","metadata":{"execution":{"iopub.status.busy":"2021-11-27T11:00:30.002019Z","iopub.execute_input":"2021-11-27T11:00:30.002281Z","iopub.status.idle":"2021-11-27T11:00:30.006394Z","shell.execute_reply.started":"2021-11-27T11:00:30.002252Z","shell.execute_reply":"2021-11-27T11:00:30.005434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer learning","metadata":{}},{"cell_type":"code","source":"# Download and plot the Xception model\nxception = tfk.applications.Xception(\n    include_top=False, # we don't want to include the classifier \n    weights=\"imagenet\", \n    input_shape=input_shape\n)\nxception.summary()\ntfk.utils.plot_model(xception)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-27T11:00:53.939367Z","iopub.execute_input":"2021-11-27T11:00:53.940121Z","iopub.status.idle":"2021-11-27T11:01:00.955689Z","shell.execute_reply.started":"2021-11-27T11:00:53.940082Z","shell.execute_reply":"2021-11-27T11:01:00.951187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We freeze the convolutional layers in order to train only our classifier \nxception.trainable = False\n\n\n# Classifier\ninputs = tfk.Input(input_shape)\nx = tfkl.Resizing(256, 256, interpolation=\"bicubic\")(inputs)\nx = xception(x)\n#instead of flattening we use a global average pooling layer (better results, see reports for details)\nx = tfkl.GlobalAveragePooling2D(name='GlobalPooling')(x) #global average pooling reduces the number of training parameters\nx = tfkl.Dropout(0.3, seed=seed)(x) #dropout layer in order to reduce overfitting\nx = tfkl.Dense(\n    256, \n    activation='relu',\n    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\nx = tfkl.Dropout(0.3, seed=seed)(x)\noutputs = tfkl.Dense(\n    14, \n    activation='softmax',\n    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n\n\n# Connect input and output through the Model class\nxe= tfk.Model(inputs=inputs, outputs=outputs, name='model')\n\n# Compile the model\nxe.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\nxe.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-27T11:05:32.007909Z","iopub.execute_input":"2021-11-27T11:05:32.00819Z","iopub.status.idle":"2021-11-27T11:05:32.375726Z","shell.execute_reply.started":"2021-11-27T11:05:32.00816Z","shell.execute_reply":"2021-11-27T11:05:32.374978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nxe_history = xe.fit(\n    x = train_gen,\n    epochs = epochs,\n    validation_data = valid_gen,\n    class_weight = weights,\n    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n).history","metadata":{"execution":{"iopub.status.busy":"2021-11-24T19:49:54.197035Z","iopub.execute_input":"2021-11-24T19:49:54.197888Z","iopub.status.idle":"2021-11-24T19:50:09.677322Z","shell.execute_reply.started":"2021-11-24T19:49:54.197838Z","shell.execute_reply":"2021-11-24T19:50:09.676243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xe.save(\"myModels/final0\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training\nplt.figure(figsize=(15,5))\nplt.plot(xe_history['loss'], label='Training', alpha=.3, color='#ff7f0e', linestyle='--')\nplt.plot(xe_history['val_loss'], label='Validation', alpha=.8, color='#ff7f0e')\nplt.legend(loc='upper left')\nplt.title('Categorical Crossentropy')\nplt.grid(alpha=.3)\n\nplt.figure(figsize=(15,5))\nplt.plot(xe_history['accuracy'], label='Training', alpha=.8, color='#ff7f0e', linestyle='--')\nplt.plot(xe_history['val_accuracy'], label='Validation', alpha=.8, color='#ff7f0e')\nplt.legend(loc='upper left')\nplt.title('Accuracy')\nplt.grid(alpha=.3)\n\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine Tuning","metadata":{}},{"cell_type":"code","source":"# Set all Xception layers to True\nxe.get_layer('xception').trainable = True\nfor i, layer in enumerate(xe.get_layer('xception').layers):\n   print(i, layer.name, layer.trainable)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T11:07:15.362797Z","iopub.execute_input":"2021-11-27T11:07:15.363602Z","iopub.status.idle":"2021-11-27T11:07:15.431347Z","shell.execute_reply.started":"2021-11-27T11:07:15.363562Z","shell.execute_reply":"2021-11-27T11:07:15.430625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze first 65 layers to keep the most generic filters untouched\nfor i, layer in enumerate(xe.get_layer('xception').layers[:65]):\n  layer.trainable=False\nfor i, layer in enumerate(xe.get_layer('xception').layers):\n   print(i, layer.name, layer.trainable)\nxe.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-27T11:07:39.25402Z","iopub.execute_input":"2021-11-27T11:07:39.254301Z","iopub.status.idle":"2021-11-27T11:07:39.326302Z","shell.execute_reply.started":"2021-11-27T11:07:39.254259Z","shell.execute_reply":"2021-11-27T11:07:39.325599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Compile the model\nxe.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-27T11:07:55.332423Z","iopub.execute_input":"2021-11-27T11:07:55.332941Z","iopub.status.idle":"2021-11-27T11:07:55.346044Z","shell.execute_reply.started":"2021-11-27T11:07:55.332904Z","shell.execute_reply":"2021-11-27T11:07:55.345277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Utility function to create folders and callbacks (allows to log some informations at runtime during training) for training\nfrom datetime import datetime\n\ndef create_folders_and_callbacks(model_name):\n\n  exps_dir = os.path.join('data_augmentation_experiments')\n  if not os.path.exists(exps_dir):\n      os.makedirs(exps_dir)\n\n  now = datetime.now().strftime('%b%d_%H-%M-%S')\n\n  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n  if not os.path.exists(exp_dir):\n      os.makedirs(exp_dir)\n      \n  callbacks = []\n\n  # Model checkpoint: allows to automatically save the model during training\n  # ----------------\n  ckpt_dir = os.path.join(exp_dir, 'ckpts') \n  if not os.path.exists(ckpt_dir):\n      os.makedirs(ckpt_dir)\n\n\n  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp'),#where i want to save the checkpoints\n                                                     save_weights_only=False, \n                                                     save_best_only=False)  \n\n  callbacks.append(ckpt_callback)\n\n  # Visualize Learning on Tensorboard\n  # ---------------------------------\n  tb_dir = os.path.join(exp_dir, 'tb_logs')\n  if not os.path.exists(tb_dir):\n      os.makedirs(tb_dir)\n      \n  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n                                               profile_batch=0,\n                                               histogram_freq=1) \n  callbacks.append(tb_callback)\n\n  # Early Stopping\n  # --------------\n  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='max',patience=10, restore_best_weights=True)\n  callbacks.append(es_callback)\n    \n\n  return callbacks","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mycallbacks = create_folders_and_callbacks(model_name='FinalModel')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fine-tune the model\nxef_history = xe.fit(\n    x = train_gen,\n    batch_size = 256,\n    epochs = epochs,\n    validation_data = valid_gen,\n    class_weight = weights,\n    callbacks = mycallbacks\n).history","metadata":{"execution":{"iopub.status.busy":"2021-11-25T06:38:40.341335Z","iopub.execute_input":"2021-11-25T06:38:40.342249Z","iopub.status.idle":"2021-11-25T06:38:55.582077Z","shell.execute_reply.started":"2021-11-25T06:38:40.342195Z","shell.execute_reply":"2021-11-25T06:38:55.579333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training of the fined-tuned model compared with the non fined-tuned one\nplt.figure(figsize=(15,5))\n\nplt.plot(xe_history['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\nplt.plot(xe_history['val_loss'], label='Transfer Learning', alpha=.8, color='#ff7f0e')\n\nplt.plot(xef_history['loss'], alpha=.3, color='#4D61E2', linestyle='--')\nplt.plot(xef_history['val_loss'], label='Fine Tuning', alpha=.8, color='#4D61E2')\nplt.legend(loc='upper left')\nplt.title('Categorical Crossentropy')\nplt.grid(alpha=.3)\n\nplt.figure(figsize=(15,5))\n\nplt.plot(xe_history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\nplt.plot(xe_history['val_accuracy'], label='Transfer Learning', alpha=.8, color='#ff7f0e')\n\nplt.plot(xef_history['accuracy'], alpha=.3, color='#4D61E2', linestyle='--')\nplt.plot(xef_history['val_accuracy'], label='Fine Tuning', alpha=.8, color='#4D61E2')\nplt.legend(loc='upper left')\nplt.title('Accuracy')\nplt.grid(alpha=.3)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nxe.save(\"myModels/f_final0\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing the model","metadata":{}},{"cell_type":"code","source":"# Predict the test set with the CNN\npredictions = xe.predict(test_gen)\npredictions.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-23T20:44:38.741074Z","iopub.execute_input":"2021-11-23T20:44:38.741316Z","iopub.status.idle":"2021-11-23T20:44:51.065662Z","shell.execute_reply.started":"2021-11-23T20:44:38.741283Z","shell.execute_reply":"2021-11-23T20:44:51.064991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confution Matrix and Classification Report\nY_pred = xe.predict_generator(test_gen, 1786 // 20+1)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nplt.figure(figsize=(10,8))\ncm = confusion_matrix(test_gen.classes, y_pred)\nsns.heatmap(cm.T, xticklabels=labels, yticklabels=labels)\nplt.xlabel('True labels')\nplt.ylabel('Predicted labels')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T18:32:18.104063Z","iopub.execute_input":"2021-11-23T18:32:18.104339Z","iopub.status.idle":"2021-11-23T18:32:18.109525Z","shell.execute_reply.started":"2021-11-23T18:32:18.104307Z","shell.execute_reply":"2021-11-23T18:32:18.108732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Classification Report')\nprint(classification_report(test_gen.classes, y_pred, target_names=labels))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T20:44:51.066788Z","iopub.execute_input":"2021-11-23T20:44:51.06706Z","iopub.status.idle":"2021-11-23T20:44:51.486933Z","shell.execute_reply.started":"2021-11-23T20:44:51.06701Z","shell.execute_reply":"2021-11-23T20:44:51.486305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the target images and the predictions\nbatch = next(test_gen)\nbatch_pr = xe.predict(batch[0])\nind=random.randint(0,19)\nfig, (ax1, ax2) = plt.subplots(1,2)\nfig.set_size_inches(18,5)\n\nimage = batch[0][ind]\nax1.imshow(image)\ncat_label = batch[1][ind]\n\n\nlabel_index = np.argmax(cat_label)\nax1.set_title('True label: '+labels[label_index])\nax2.barh(labels, batch_pr[ind], color=plt.get_cmap('Paired').colors, log=True)\nax2.set_title('Predicted label: '+labels[np.argmax(batch_pr[ind])])\nax2.grid(alpha=.3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T20:50:10.790522Z","iopub.execute_input":"2021-11-23T20:50:10.790784Z","iopub.status.idle":"2021-11-23T20:50:16.623039Z","shell.execute_reply.started":"2021-11-23T20:50:10.790753Z","shell.execute_reply":"2021-11-23T20:50:16.622361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"layers = [layer.output for layer in xe.layers[2].layers if isinstance(layer, tf.keras.layers.Conv2D)]\nactivation_model = tf.keras.Model(inputs=xe.layers[2].input, outputs=layers)\nfmaps = activation_model.predict(tf.expand_dims(image, 0))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T20:50:23.881299Z","iopub.execute_input":"2021-11-23T20:50:23.882314Z","iopub.status.idle":"2021-11-23T20:50:23.895309Z","shell.execute_reply.started":"2021-11-23T20:50:23.882268Z","shell.execute_reply":"2021-11-23T20:50:23.894596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n%matplotlib inline\ndef display_activation(fmaps, depth=0, first_n=-1):\n\n    fmaps = fmaps[depth] \n    if first_n > 0:\n        fmaps = fmaps[0, :, :, :first_n] \n        fmaps = tf.image.resize(fmaps, size=[128, 128]) \n\n    # Distribute on a grid for plotting\n    col_size = 8\n    row_size = fmaps.shape[-1] // 8\n    fmap_channel=0\n    fig = plt.figure(figsize=(30, 30))\n    grid = ImageGrid(fig, 111,  \n                    nrows_ncols=(row_size, col_size),  \n                    axes_pad=0.1,  \n                    )\n    for row in range(0,row_size):\n        for col in range(0,col_size):\n            grid[fmap_channel].imshow(fmaps[0, :, :, fmap_channel], cmap='gray', aspect='auto')\n            fmap_channel += 1\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_activation(fmaps=fmaps, depth=1, first_n=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}